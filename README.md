# ğŸ“‰ Customer Churn Prediction with XGBoost

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project demonstrates how to predict **customer churn** using an XGBoost classifier, with a focus on **data preprocessing**, **model training**, **hyperparameter optimization**, and **evaluation** using the popular **Telco Customer Churn dataset**.

---

## ğŸš€ Project Overview

The goal is to build a machine learning pipeline that can effectively identify customers who are likely to churn, helping businesses take preemptive actions.

### ğŸ” Key Steps in `xgboost_code.ipynb`:

* ğŸ“¥ **Data Loading** â€“ Load and explore the dataset.
* ğŸ§¹ **Data Preprocessing** â€“ Clean and encode categorical features.
* ğŸ§ª **Train-Test Split** â€“ Stratified 80/20 split of the dataset.
* âš™ï¸ **Model Training** â€“ Build a baseline XGBoost classifier.
* ğŸ” **Hyperparameter Tuning** â€“ Optimize model using `GridSearchCV`.
* ğŸ“Š **Evaluation** â€“ Assess performance using accuracy, confusion matrix, and balanced metrics.

---

## ğŸ§¾ Dataset

* **File**: `WA_Fn-UseC_-Telco-Customer-Churn.csv`
* **Rows/Columns**: 7043 Ã— 21
* **Source**: IBM Sample Data Sets (included in this repo)
* **Description**: Customer demographic data, account info, services subscribed, and churn status.

---

## ğŸ“ File Structure

```bash
â”œâ”€â”€ xgboost_code.ipynb        # Main notebook with full analysis pipeline
â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv  # Dataset
â””â”€â”€ README.md                 # Project description
```

---

## ğŸ› ï¸ Technologies Used

* **Language**: Python 3.x
* **Libraries**:

  * `pandas`, `numpy` â€“ Data wrangling
  * `scikit-learn` â€“ ML tools & evaluation
  * `xgboost` â€“ Gradient boosting model
  * `matplotlib` â€“ Confusion matrix visualization
  * `jupyterlab` or `notebook` â€“ Development environment

---

## âš™ï¸ Setup & Installation

1. **Clone the repo**

   ```bash
   git clone https://github.com/Kaviii8/xgboost-for-data-classification.git
   cd customer-churn-xgboost
   ```

2. **Create a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   Create `requirements.txt`:

   ```txt
   pandas
   numpy
   scikit-learn
   xgboost
   matplotlib
   jupyterlab
   ```

   Install:

   ```bash
   pip install -r requirements.txt
   ```

4. **Launch Jupyter**

   ```bash
   jupyter notebook
   ```

---

## ğŸ“ˆ Results Summary

### âœ… Best Parameters from Grid Search:

| Parameter          | Value |
| ------------------ | ----- |
| `max_depth`        | 3     |
| `learning_rate`    | 0.1   |
| `n_estimators`     | 100   |
| `gamma`            | 0.1   |
| `subsample`        | 0.7   |
| `colsample_bytree` | 0.7   |
| `lambda`           | 10    |
| `alpha`            | 1     |

### ğŸ§ª Performance Evaluation:

* `balanced_accuracy_score` used for fair assessment on imbalanced data
* Confusion matrix plotted using `ConfusionMatrixDisplay`
* Results clearly documented in the final notebook cell

---

## ğŸ¤ Contributing

Got suggestions or found a bug? Contributions are welcome!

* ğŸ“¥ Fork the repository
* ğŸ“Œ Create a new branch
* âœ… Submit a pull request

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---
